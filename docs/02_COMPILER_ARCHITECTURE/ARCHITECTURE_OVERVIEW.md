# Baa Language Architecture

---
**Status:** Core Infrastructure Production-Ready âœ… | Semantic Analysis & Code Generation Planned ðŸ“‹
**Last Updated:** 2025-11-06
**Version:** v0.1.15+
**Priority 4 Status:** Completed (Preprocessor, Lexer, Parser, AST with Function Support)

---

## Overview

Baa (Ø¨Ø§Ø¡) is designed with a modular architecture that separates concerns into distinct components. Each component is responsible for a specific aspect of the compilation process, making the system maintainable and extensible. **As of 2025-11-06, the core compiler infrastructure is production-ready with Priority 4 (Function Definitions and Calls) completed.**

## Core Components

### 0. Preprocessor (Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø³Ø¨Ù‚) âœ… Production-Ready

The initial stage that processes the source file before tokenization:

- **Directive Handling**: Processes directives like `#ØªØ¶Ù…ÙŠÙ†` (include) and `#ØªØ¹Ø±ÙŠÙ` (define).
- **File Inclusion**: Merges included files into a single stream.
- **Macro Expansion**: Substitutes defined object-like and function-like macros. Supports stringification (`#`) and token pasting (`##`). Detects recursive expansion.
- **Input Encoding**: Expects UTF-16LE input files (checks BOM), or UTF-8 (with/without BOM, auto-detected and converted to UTF-16LE internally).
- **Output**: Produces a single `wchar_t*` stream (UTF-16LE) for the lexer.
- **Circular Include Detection**: Prevents infinite include loops.
- **Conditional Compilation**: Handles `#Ø¥Ø°Ø§`, `#Ø¥Ø°Ø§_Ø¹Ø±Ù`, `#Ø¥Ø°Ø§_Ù„Ù…_ÙŠØ¹Ø±Ù`, `#ÙˆØ¥Ù„Ø§_Ø¥Ø°Ø§`, `#Ø¥Ù„Ø§`, `#Ù†Ù‡Ø§ÙŠØ©_Ø¥Ø°Ø§`. Evaluates constant integer expressions for `#Ø¥Ø°Ø§`/`#ÙˆØ¥Ù„Ø§_Ø¥Ø°Ø§` (supports arithmetic, comparison, logical, bitwise operators, `Ù…Ø¹Ø±Ù()`).
- **Error Reporting**: Reports errors with file path and line number context. Accumulates multiple diagnostics.
- **Features & Status:**
  - Implemented as a separate stage.
  - Handles `#ØªØ¶Ù…ÙŠÙ†` (relative and standard paths).
  - Handles `#ØªØ¹Ø±ÙŠÙ` (object-like and function-like macros, including `#`, `##`, variadic, and **rescanning of expansion results**).
  - Handles `#Ø§Ù„ØºØ§Ø¡_ØªØ¹Ø±ÙŠÙ` to undefine macros.
  - Handles conditional compilation (`#Ø¥Ø°Ø§_Ø¹Ø±Ù`, `#Ø¥Ø°Ø§_Ù„Ù…_ÙŠØ¹Ø±Ù`, `#Ø¥Ù„Ø§`, `#Ù†Ù‡Ø§ÙŠØ©_Ø¥Ø°Ø§`, `#Ø¥Ø°Ø§`, `#ÙˆØ¥Ù„Ø§_Ø¥Ø°Ø§`) with expression evaluation (using `Ù…Ø¹Ø±Ù` for `defined`).
  - Supports `#Ø®Ø·Ø£` and `#ØªØ­Ø°ÙŠØ±` directives.
  - Detects circular includes and recursive macro expansion.
  - Provides predefined macros (`__Ø§Ù„Ù…Ù„Ù__`, `__Ø§Ù„Ø³Ø·Ø±__` (int), `__Ø§Ù„ØªØ§Ø±ÙŠØ®__`, `__Ø§Ù„ÙˆÙ‚Øª__`, `__Ø§Ù„Ø¯Ø§Ù„Ø©__` (placeholder), `__Ø¥ØµØ¯Ø§Ø±_Ø§Ù„Ù…Ø¹ÙŠØ§Ø±_Ø¨Ø§Ø¡__`).
  - *See `docs/PREPROCESSOR_ROADMAP.md` for latest status, including error recovery enhancements.*

### 1. Lexer âœ… Production-Ready

The lexical analyzer responsible for tokenizing source code. It has a modular structure:

- `lexer.c`: Core dispatch logic (`baa_lexer_next_token`) and helper functions.
- `token_scanners.c`: Implements specific scanning functions for identifiers, numbers, strings, and comments.
- `lexer_char_utils.c`: Provides character classification utilities (e.g., for Arabic letters, digits).
- **Token Generation**: Converts source text (UTF-16LE output from preprocessor) into a stream of tokens.
- **Unicode Support**: Full support for Arabic characters in identifiers, literals, and keywords. Recognizes Arabic-Indic digits.
- **Source Tracking**: Accurate line and column tracking for tokens and errors.
- **Enhanced Error Handling**: Comprehensive error detection and reporting system with:
  - **Specific Error Types**: 8 distinct error token types (unterminated strings/chars/comments, invalid escapes/numbers/suffixes/characters)
  - **Error Codes**: Unique codes (1001-1009, 9001) for internationalization and categorization
  - **Arabic Messages**: All error messages and suggestions provided in Arabic
  - **Rich Context**: Error categories, helpful suggestions, and precise source location tracking
  - **Error Recovery**: Robust synchronization to continue tokenizing after errors
- **Whitespace and Newlines**: Tokenizes spaces/tabs (`BAA_TOKEN_WHITESPACE`) and newlines (`BAA_TOKEN_NEWLINE`) separately.
- **Comment Handling**: Tokenizes single-line (`//` -> `BAA_TOKEN_SINGLE_LINE_COMMENT`), multi-line (`/*...*/` -> `BAA_TOKEN_MULTI_LINE_COMMENT`), and documentation comments (`/**...*/` -> `BAA_TOKEN_DOC_COMMENT`). Lexemes for comments contain the content excluding delimiters.
- **Numeric Literal Recognition**:
  - Identifies various number formats: integers (decimal, binary `0b`/`0B`, hexadecimal `0x`/`0X`), floats (using `.` or `Ù«` as decimal separator).
  - Uses Arabic exponent marker `Ø£` for scientific notation (English `e`/`E` are not supported) - fully implemented and working.
  - Supports Arabic-Indic digits (`Ù `-`Ù©`) and Western digits (`0`-`9`) within all parts of numbers.
  - Supports underscores (`_`) as separators for readability in numbers.
  - Tokenizes Arabic integer literal suffixes (`Øº`, `Ø·`, `Ø·Ø·`) and float suffix (`Ø­`) - fully implemented and working.
  - The lexer's `scan_number` function handles syntactic recognition and extracts the raw lexeme. The separate `number_parser.c` utility converts these lexemes to actual numeric values.
- **String/Char Literals**: Handles string (`"..."`, `"""..."""` multiline, `Ø®"..."` raw) and character (`'...'`) literals.
  - Processes **Baa-specific Arabic escape sequences** (e.g., `\Ø³` for newline, `\Ù…` for tab, `\ÙŠXXXX` for Unicode, `\Ù‡Ù€HH` for hex byte) - fully implemented and working in all string types.
  - Standard C escapes like `\n`, `\t`, `\uXXXX` are **not** supported and will result in errors.
- **Features & Status:**
  - Core lexer functionality and modular structure are implemented.
  - Robust token handling for keywords, identifiers, operators, and various literal types.
  - String and character literal support with Baa-specific escapes (conceptually).
  - Source position tracking.
  - Error token generation.
  - *See `docs/LEXER_ROADMAP.md` for detailed status and planned enhancements.*

### 2. Parser âœ… Production-Ready

Transforms tokens into a structured AST:

- **Status**: Production-ready with Priority 4 completed (v0.1.15+). Function definitions, function calls, and core language constructs fully implemented.
- **Approach**: Recursive descent.
- **Output**: Abstract Syntax Tree (AST) composed of `BaaNode`s.
- **Error Handling**: Syntax error detection, reporting, and panic mode recovery.
- **Completed Features**: Variable declarations, expressions (literals, identifiers, binary, unary, calls), statements (if, while, for, return, block), function definitions with parameters.
- *Refer to [`docs/PARSER.md`](PARSER.md) and [`docs/PARSER_ROADMAP.md`](../04_ROADMAP/PARSER_ROADMAP.md) for details.*

### 3. Abstract Syntax Tree (AST) âœ… Production-Ready

The AST module provides the foundation for representing code structure using a unified `BaaNode` approach.

- **Status**: Production-ready with Priority 4 completed (v0.1.15+). All core node types implemented for expressions, statements, declarations, and functions.
- **Structure**:
  - Unified `BaaNode` with `BaaNodeKind kind`, `BaaSourceSpan span`, and `void* data`.
  - Specific data structs (e.g., `BaaLiteralExprData`, `BaaFunctionDefData`, `BaaCallExprData`) for each node kind.
- **Memory Management**: `baa_ast_new_node()` for base creation, `baa_ast_free_node()` for recursive freeing.
- **Traversal**: Visitor pattern planned for AST traversal.
- **Completed Node Types**: Program, function definitions, parameters, variable declarations, expressions (literal, identifier, binary, unary, call, assignment), statements (block, if, while, for, return, expression).
- *Refer to [`docs/AST.md`](AST.md) and [`docs/AST_ROADMAP.md`](../04_ROADMAP/AST_ROADMAP.md) for details.*

### 4. Type System

A robust type system that supports both C compatibility and Arabic type names:

- **Basic Types**: `Ø¹Ø¯Ø¯_ØµØ­ÙŠØ­` (int), `Ø¹Ø¯Ø¯_Ø­Ù‚ÙŠÙ‚ÙŠ` (float), `Ø­Ø±Ù` (char), `Ù…Ù†Ø·Ù‚ÙŠ` (bool), `ÙØ±Ø§Øº` (void).
- **Type Checking**: Static type checking (planned for Semantic Analysis).
- **Type Conversion**: Implicit and explicit type conversion rules (planned for Semantic Analysis).
- **Features & Status:**
  - Core type definitions and structures implemented.
  - Array type structure (`BAA_TYPE_ARRAY`) defined.

### 5. Operators

Operator system with full Arabic support:

- **Arithmetic**: `+`, `-`, `*`, `/`, `%`
- **Comparison**: `==`, `!=`, `>`, `<`, `>=`, `<=`
- **Logical**: Uses symbols `&&` (Ùˆ - AND), `||` (Ø£Ùˆ - OR), `!` (Ù„ÙŠØ³ - NOT).
- **Precedence**: Clear operator precedence rules defined.
- **Features & Status:**
  - Operator definitions, symbols, and precedence implemented.
  - Basic validation stubs exist.

### 6. Control Flow (Semantic and AST Representation)

Control structures with Arabic keywords:

- **Conditions**: `Ø¥Ø°Ø§` (if), `ÙˆØ¥Ù„Ø§` (else)
- **Loops**: `Ø·Ø§Ù„Ù…Ø§` (while), `Ù„ÙƒÙ„` (for)
- **Functions**: (Uses C-style declarations)
- **Return**: `Ø¥Ø±Ø¬Ø¹` (return)
- **Status**: Keywords tokenized by Lexer. Parser rules and AST node definitions are part of the new Parser/AST design (ongoing). Semantic validation planned.

### 7. Utils

Utility functions and support features:

- **Error Handling**: Basic error enums and reporting functions.
- **Memory Management**: Safe memory allocation wrappers (`baa_malloc`, `baa_free`, `baa_strdup`).
- **String Handling**: UTF-16LE wide character string operations.
- **File Operations**: Source file handling with UTF-8/UTF-16LE auto-detection (in preprocessor) and UTF-16LE processing (in lexer).
- **Features & Status:** Implemented.

### 8. Semantic Analysis ðŸ“‹ Planned

Responsible for verifying static semantics, name resolution, and type checking.

- **Status**: Planned for future implementation. Basic flow analysis structure exists (`src/analysis/`), but full semantic analysis awaits completion.
- **Features (Planned):**
  - Symbol table management and scope handling.
  - Name resolution (linking identifiers to declarations).
  - Comprehensive type checking and inference.
  - Control flow analysis (reachability, return paths).
  - AST annotation with semantic information.
  - *See [`docs/SEMANTIC_ANALYSIS.md`](SEMANTIC_ANALYSIS.md) and [`docs/SEMANTIC_ANALYSIS_ROADMAP.md`](../04_ROADMAP/SEMANTIC_ANALYSIS_ROADMAP.md).*

### 9. Code Generation ðŸ“‹ Planned

Transforms the (semantically analyzed) AST into executable code or intermediate representation.

- **Status**: Planned for future implementation. Basic LLVM integration stubs and conditional build logic exist. Actual IR generation from AST is pending.
- **Features (Planned):**
  - LLVM IR generation from the semantically-analyzed AST.
  - Optimization passes, debug information, source mapping.
  - Support for multiple target platforms (x86-64, ARM64, Wasm).
  - *See [`docs/CODE_GENERATION.md`](CODE_GENERATION.md) and [`docs/LLVM_CODEGEN_ROADMAP.md`](../04_ROADMAP/LLVM_CODEGEN_ROADMAP.md).*

## Build System

The build system is based on CMake and provides:

- **Component Management**: Each component built as a separate static library.
- **Test Integration**: Automated testing for each component (via CTest).
- **Cross-Platform**: Support for multiple operating systems.
- **Configuration**: Flexible build configuration options (e.g., `USE_LLVM`).

## Testing Framework

Comprehensive testing infrastructure:

- **Unit Tests**: Tests for individual components (`tests/unit/`).
- **Integration Tests**: Tests for component interaction (planned in `tests/integration/`).
- **Arabic Test Cases**: Test cases with Arabic input (`tests/resources/`).
- **Framework**: Simple assertion-based test framework in `tests/framework/`.

## Error Handling

Comprehensive error handling system with enhanced lexical error support:

### Lexical Error Handling âœ… (Fully Implemented)
- **Specific Error Types**: 8 distinct error token types with unique error codes
- **Error Categories**: Organized by type (string, escape, character, number, comment, memory, operator)
- **Arabic Localization**: Complete Arabic error messages and actionable suggestions
- **Rich Context**: Error codes, categories, suggestions, and enhanced source location tracking
- **Error Recovery**: Robust synchronization mechanisms to continue after errors
- **Memory Management**: Proper cleanup of error contexts and enhanced token structures

### Other Error Types
- **Preprocessor Errors**: File inclusion, macro expansion, conditional compilation errors
- **Parser Errors**: Syntax error detection, reporting, and basic panic mode recovery (planned)
- **Semantic Errors**: Type checking, scope resolution errors (planned)
- **CodeGen Errors**: Code generation and optimization errors (planned)

### Error Reporting Features
- **Source Location**: Precise error reporting with file, line, and column information
- **Enhanced Spans**: Start/end positions and character offsets for better IDE integration
- **Error Codes**: Unique numeric codes for internationalization and tooling support

## Memory Management

Memory management strategy:

- **Manual Allocation**: Uses custom wrappers (`baa_malloc`, `baa_free`, `baa_strdup`) around standard library functions for potential tracking or replacement.
- **Ownership Rules**: Components are responsible for freeing memory they allocate (e.g., lexer allocates tokens, parser/AST manages AST nodes).

## Future Extensions

Planned enhancements:

- Comprehensive Semantic Analysis and Code Generation.
- Full Standard Library implementation.
- Optimizer passes.
- IDE Integration (LSP).
